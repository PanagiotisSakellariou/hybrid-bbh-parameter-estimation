{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746fa1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code make scatter plots for true vs predicted values for many models\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38549e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"white\", palette='tab10')\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "else:\n",
    "    print('No GPU found for TensorFlow.')\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('\\nUsing device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9304fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterTensorFlowToPyTorchDataset(IterableDataset):\n",
    "    def __init__(self, tf_dataset_path):\n",
    "        \"\"\"\n",
    "        A PyTorch dataset that fetches data from a TensorFlow dataset.\n",
    "        \n",
    "        Args:\n",
    "        - tf_dataset: A TensorFlow dataset.\n",
    "        \"\"\"\n",
    "        self.tf_path = tf_dataset_path\n",
    "        self.tf_dataset = tf.data.Dataset.load(tf_dataset_path)\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return tf.data.experimental.cardinality(self.tf_dataset).numpy()\n",
    "            \n",
    "    def __iter__(self):\n",
    "        for element in self.tf_dataset.as_numpy_iterator():\n",
    "            features, labels = element\n",
    "            features = torch.tensor(features, dtype=torch.float32).view(1, -1)  # Reshape to match model input shape\n",
    "            labels = torch.tensor(labels, dtype=torch.float32)\n",
    "            \n",
    "            # # Normalize the labels\n",
    "            # labels = self.output_normalization(labels)\n",
    "    \n",
    "            yield features, labels\n",
    "    \n",
    "    def size(self, in_gb=False):\n",
    "        ''' Returns the size of the Dataset in MB or GB.\n",
    "        '''\n",
    "        if os.path.exists(self.tf_path):\n",
    "            if os.path.isfile(self.tf_path):\n",
    "                # If it's a single file\n",
    "                size_in_bytes = os.path.getsize(self.tf_path)\n",
    "            elif os.path.isdir(self.tf_path):\n",
    "                # If it's a directory, sum up the sizes of all files inside it\n",
    "                size_in_bytes = sum(\n",
    "                    os.path.getsize(os.path.join(root, file))\n",
    "                    for root, _, files in os.walk(self.tf_path)\n",
    "                    for file in files\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(f\"Path '{self.tf_path}' is neither a file nor a directory.\")\n",
    "            \n",
    "                            \n",
    "            if in_gb == False:\n",
    "                size_in_mb = size_in_bytes / (1024*1024) # Convert to MB\n",
    "                return size_in_mb\n",
    "            else:\n",
    "                size_in_gb = size_in_bytes / (1024*1024*1024) # Convert to GB\n",
    "                return size_in_gb\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Data file not found at {self.tf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0d2384",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/sakellariou/hero_disk/test/'  # <--- Change this to the path of the dataset\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "# Load data from Tensorflow dataset\n",
    "print('\\nLoading data with noise')\n",
    "train_dataset = IterTensorFlowToPyTorchDataset(path + 'train_dataset')\n",
    "val_dataset = IterTensorFlowToPyTorchDataset(path + 'val_dataset')\n",
    "test_dataset = IterTensorFlowToPyTorchDataset(path + 'test_dataset')\n",
    "  \n",
    "print('\\nNumber of training samples:', len(train_dataset))\n",
    "print('Number of validation samples:', len(val_dataset))\n",
    "print('Number of test samples:', len(test_dataset))\n",
    "\n",
    "print(f'\\nSize of training dataset: {train_dataset.size(in_gb=True):.3f} GB')\n",
    "print(f'Size of validation dataset: {val_dataset.size(in_gb=True):.3f} GB')\n",
    "print(f'Size of test dataset: {test_dataset.size(in_gb=True):.3f} GB')\n",
    "\n",
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Create DataLoader for batching\n",
    "print('\\nCreating DataLoaders...')\n",
    "batch = 1024\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch, shuffle=False) # ItterableDataset is not shuffleable\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f226549a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models -----------------------------------------------------------------------------------------------\n",
    "\n",
    "# ShallowModel\n",
    "class ShallowModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Shallow CNN model for regression.\n",
    "    \n",
    "    The model requires initialization before loading weights. \n",
    "    To initialize the model, call model.initialize(input_tensor).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_vars):\n",
    "        super(ShallowModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=16, stride=1, dilation=1)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=8, stride=1, dilation=4)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=8, stride=1, dilation=4)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = None # This layer will be initialized in the forward method\n",
    "        self.fc2 = nn.Linear(64, num_vars)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # Initialize the first fully connected layer the first time forward is run\n",
    "        if self.fc1 is None:\n",
    "            self.fc1 = nn.Linear(x.size(1), 64).to(x.device) \n",
    "            \n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def initialize(self, x):\n",
    "        \"\"\"Initialize the model by passing an input tensor.\"\"\"\n",
    "        self.forward(x)\n",
    "        print(\"\\nModel initialized successfully.\")\n",
    "\n",
    "\n",
    "# DeepModel\n",
    "class DeepModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Deep CNN model for regression.\n",
    "    \n",
    "    The model requires initialization before loading weights. \n",
    "    To initialize the model, call model.initialize(input_tensor).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_vars):\n",
    "        super(DeepModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=16, stride=1, dilation=1)\n",
    "        # self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=16, stride=1, dilation=2)\n",
    "        # self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=16, stride=1, dilation=2)\n",
    "        # self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(256, 512, kernel_size=32, stride=1, dilation=2)\n",
    "        # self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.pool4 = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = None # This layer will be initialized in the forward method\n",
    "        # self.drp1 = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        # self.drp2 = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(64, num_vars)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # x = self.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        # x = self.bn2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        # x = self.bn3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        # x = self.bn4(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # Initialize the first fully connected layer the first time forward is run\n",
    "        if self.fc1 is None:\n",
    "            self.fc1 = nn.Linear(x.size(1), 128).to(x.device)\n",
    "            \n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        # x = self.drp1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "        # x = self.drp2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def initialize(self, x):\n",
    "        \"\"\"Initialize the model by passing an input tensor.\"\"\"\n",
    "        self.forward(x)\n",
    "        print(\"\\nModel initialized successfully.\")\n",
    "\n",
    "# BNSModel\n",
    "class BNSModel(nn.Module):\n",
    "    \"\"\"\n",
    "    BNS CNN model for regression based on the paper\n",
    "    ~Detection and parameter estimation of gravitational \n",
    "    waves from binary neutron-star mergers in real LIGO \n",
    "    data using deep learning~.\n",
    "    \n",
    "    The model requires initialization before loading weights. \n",
    "    To initialize the model, call model.initialize(input_tensor).\n",
    "    \"\"\"\n",
    "    def __init__(self, num_vars):\n",
    "        super(BNSModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=16)\n",
    "        # self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=4)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=8)\n",
    "        # self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=4)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=8)\n",
    "        # self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=4)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(128, 256, kernel_size=8)\n",
    "        # self.bn4 = nn.BatchNorm1d(256)\n",
    "        self.pool4 = nn.MaxPool1d(kernel_size=4)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = None # This layer will be initialized in the forward method\n",
    "        # self.drp1 = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        # self.drp2 = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(64, num_vars)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # x = self.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        # x = self.bn2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        # x = self.bn3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        # x = self.bn4(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # Initialize the first fully connected layer the first time forward is run\n",
    "        if self.fc1 is None:\n",
    "            self.fc1 = nn.Linear(x.size(1), 128).to(x.device)\n",
    "            \n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        # x = self.drp1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "        # x = self.drp2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def initialize(self, x):\n",
    "        \"\"\"Initialize the model by passing an input tensor.\"\"\"\n",
    "        self.forward(x)\n",
    "        print(\"\\nModel initialized successfully.\")\n",
    "\n",
    "\n",
    "# ShallowModel-hybrid\n",
    "class HybridShallowModel(nn.Module):\n",
    "    def __init__(self, num_vars):\n",
    "        super(HybridShallowModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=16, stride=1, dilation=1)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=8, stride=1, dilation=4)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=8, stride=1, dilation=4)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=64, nhead=4) # embedding size = 64, 4 heads\n",
    "        self.transformer  = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64, 64)\n",
    "        self.fc2 = nn.Linear(64, num_vars)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        # Prepare for Transformer\n",
    "        # Transpose to match Encoder input shape: (sequence_length, batch_size, embed_dim)\n",
    "        x = x.permute(2, 0, 1)\n",
    "        \n",
    "        x = self.transformer(x)  # Output: (sequence_length, batch_size, embed_dim)\n",
    "        x = x[-1, :, :]  # Take the last sequence element (batch_size, embed_dim) \n",
    "            \n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def initialize(self, x):\n",
    "        \"\"\"Initialize the model by passing an input tensor.\"\"\"\n",
    "        self.forward(x)\n",
    "        print(\"\\nModel initialized successfully.\")\n",
    "\n",
    "# BNSModel-hybrid\n",
    "class HybridBNSModel(nn.Module):\n",
    "    def __init__(self, num_vars):\n",
    "        super(HybridBNSModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=16)\n",
    "        # self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=4)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=8)\n",
    "        # self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=4)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=8)\n",
    "        # self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=4)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(128, 256, kernel_size=8)\n",
    "        # self.bn4 = nn.BatchNorm1d(256)\n",
    "        self.pool4 = nn.MaxPool1d(kernel_size=4)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=256, nhead=4) # embedding size = 128, 4 heads\n",
    "        self.transformer  = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        # self.drp1 = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        # self.drp2 = nn.Dropout(0.2)\n",
    "        self.fc3 = nn.Linear(64, num_vars)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        # x = self.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        # x = self.bn2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        # x = self.bn3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        # x = self.bn4(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        # Prepare for Transformer\n",
    "        # Transpose to match Encoder input shape: (sequence_length, batch_size, embed_dim)\n",
    "        x = x.permute(2, 0, 1)\n",
    "        \n",
    "        x = self.transformer(x)  # Output: (sequence_length, batch_size, embed_dim)\n",
    "        x = x[-1, :, :]  # Take the last sequence element (batch_size, embed_dim)\n",
    "            \n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        # x = self.drp1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "        # x = self.drp2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def initialize(self, x):\n",
    "        \"\"\"Initialize the model by passing an input tensor.\"\"\"\n",
    "        self.forward(x)\n",
    "        print(\"\\nModel initialized successfully.\")\n",
    "            \n",
    "# DeepModel-hybrid\n",
    "class HybridDeepModel(nn.Module):\n",
    "    def __init__(self, num_variables):\n",
    "        super(HybridDeepModel, self).__init__()\n",
    "        \n",
    "        # CNN Layers\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=16, stride=1, dilation=1)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=16, stride=1, dilation=2)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=16, stride=1, dilation=2)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(256, 512, kernel_size=32, stride=1, dilation=2)\n",
    "        self.pool4 = nn.MaxPool1d(kernel_size=4, stride=4)\n",
    "\n",
    "        # Normalization before Transformer\n",
    "        self.norm = nn.LayerNorm(512)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=4, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(512, 128)  # Adjust input size based on the output of the last conv layer\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_variables)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # CNN Feature Extraction\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = torch.relu(x)   \n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool4(x) \n",
    "        \n",
    "        # Prepare for Transformer\n",
    "        # Transpose to match Encoder input shape: (batch_size, sequence_length, embed_dim)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        x = self.norm(x)\n",
    "\n",
    "        x = self.transformer(x)  # Output: (sequence_length, batch_size, embed_dim)\n",
    "        x = x[:, -1, :]  # Take the last sequence element (batch_size, embed_dim)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def initialize(self, x):\n",
    "        \"\"\"Initialize the model by passing an input tensor.\"\"\"\n",
    "        self.forward(x)\n",
    "        print(\"Model initialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f41f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------\n",
    "# Initialize model, loss function, and optimizer\n",
    "num_vars = 6\n",
    "model1 = DeepModel(num_vars).to(device)         # <----- Change model here\n",
    "model2 = HybridDeepModel(num_vars).to(device)   # <----- Change model here\n",
    "models = [model1, model2]  # Add more models as needed\n",
    "criterion = nn.L1Loss() \n",
    "\n",
    "\n",
    "# Create the destination folder if it doesn't exist\n",
    "destination_folder = f'./parameter_analysis/{model1.__class__.__name__}_{model2.__class__.__name__}_results' # <--- Change this to the desired destination folder\n",
    "if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder)\n",
    "\n",
    "# Evaluate models and collect predictions\n",
    "print('\\nEvaluating models and collecting predictions...')\n",
    "models_pred = []\n",
    "\n",
    "for model in models:\n",
    "    # Load the best model weights\n",
    "    print('\\nLoading best model weights...')\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(f'{model.__class__.__name__}_results/{model.__class__.__name__}_best_model.pth'))\n",
    "        print('\\nModel weights loaded successfully.')\n",
    "    except:\n",
    "        print('\\nError loading model weights. Initializing model...')\n",
    "        with torch.no_grad():\n",
    "            inputs, targets = next(iter(train_loader))\n",
    "            inputs = inputs.to(device)\n",
    "            model.initialize(inputs)\n",
    "        model.load_state_dict(torch.load(f'{model.__class__.__name__}_results/{model.__class__.__name__}_best_model.pth'))\n",
    "        print('\\nModel weights loaded successfully.')\n",
    "\n",
    "    print('\\nMaking evaluation metrics...')\n",
    "    model.eval()\n",
    "    all_y_true = []\n",
    "    all_y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(test_loader, desc=\"Evaluating\", dynamic_ncols=True)\n",
    "\n",
    "        for inputs, targets in progress_bar:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            test_predictions = model(inputs)\n",
    "\n",
    "            y_true = targets.cpu().numpy().astype(np.float64)\n",
    "            y_pred = test_predictions.cpu().numpy().astype(np.float64)\n",
    "            \n",
    "            \n",
    "            # Collect for plotting\n",
    "            all_y_true.append(y_true)\n",
    "            all_y_pred.append(y_pred)\n",
    "\n",
    "    # Convert lists to arrays\n",
    "    all_y_true = np.vstack(all_y_true)\n",
    "    all_y_pred = np.vstack(all_y_pred)\n",
    "    models_pred.append((all_y_true, all_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad98dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for one key parameter (e.g., primary mass = index 0)\n",
    "    \n",
    "# Define your parameter names\n",
    "param_names = ['Mass 1', 'Mass 2', 'Distance', 'Inclination', 'Spin 1', 'Spin 2'] # Mass 1 --> index=0, Mass 2 --> index=1, etc.\n",
    "\n",
    "labels = [model.__class__.__name__ for model in models]\n",
    "\n",
    "# Scatter plot for one key parameter (e.g., primary mass = index 0)\n",
    "param_index = 0  # Change to the index of the parameter you want <------\n",
    "plt.figure()\n",
    "for j, (y_true, y_pred) in enumerate(models_pred):\n",
    "    plt.scatter(y_true[:, param_index], y_pred[:, param_index], alpha=0.3, label=labels[j], s=5)\n",
    "plt.plot([all_y_true[:, param_index].min(), all_y_true[:, param_index].max()],\n",
    "        [all_y_true[:, param_index].min(), all_y_true[:, param_index].max()],\n",
    "        'r--', label='Ideal')\n",
    "plt.xlabel('True Value')\n",
    "plt.ylabel('Predicted Value')\n",
    "# plt.ylim(-10, 120)  #change limits as needed\n",
    "plt.title(f'True vs Predicted: {param_names[param_index]}')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(f'{destination_folder}/scatter_plot_{param_names[param_index].replace(\" \", \"_\")}.png',\n",
    "            bbox_inches='tight', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perfect\n",
    "fig_width, fig_height = 15, 10\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "scale = fig_width / 6\n",
    "# Parameter names\n",
    "param_names = ['Mass 1', 'Mass 2', 'Distance', 'Inclination', 'Spin 1', 'Spin 2']\n",
    "labels = [model.__class__.__name__ for model in models]\n",
    "\n",
    "\n",
    "# Loop through subplots\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    param_index = i  # Assuming param_index corresponds to i\n",
    "    for j, (y_true, y_pred) in enumerate(models_pred):\n",
    "        if j == 0:\n",
    "            ax.scatter(y_true[:, param_index], y_pred[:, param_index],\n",
    "                   alpha=0.8, label=labels[j], s=5)\n",
    "        else:\n",
    "            ax.scatter(y_true[:, param_index], y_pred[:, param_index],\n",
    "                   alpha=0.3, label=labels[j], s=5, marker='*')\n",
    "                \n",
    "        # Set tick parameters\n",
    "        ax.tick_params(axis='both', which='major', labelsize=int(9*scale))\n",
    "        \n",
    "    # Diagonal line\n",
    "    min_val = all_y_true[:, i].min()\n",
    "    max_val = all_y_true[:, i].max()\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', label='Ideal')\n",
    "    # ax.set_xlim(all_y_true[:, i].min(), all_y_true[:, i].max())\n",
    "\n",
    "    # Titles\n",
    "    ax.set_title(param_names[i], fontsize=int(12*scale))\n",
    "    \n",
    "    \n",
    "\n",
    "    # Conditional axis labels\n",
    "    row, col = divmod(i, 3)\n",
    "    if col == 0:  # Left column\n",
    "        ax.set_ylabel('Predicted', fontsize=int(10*scale))\n",
    "    else:\n",
    "        ax.set_ylabel('')  # Remove y-label\n",
    "\n",
    "    if row == 1:  # Bottom row\n",
    "        ax.set_xlabel('True', fontsize=int(10*scale))\n",
    "    else:\n",
    "        ax.set_xlabel('')  # Remove x-label\n",
    "\n",
    "# Add one legend for the whole figure\n",
    "handles, labels_ = axes.flat[0].get_legend_handles_labels()\n",
    "# fig.legend(handles, labels_, loc='upper right', ncol=len(labels_) + 1)\n",
    "\n",
    "fig.legend(handles, labels_, loc='upper center', bbox_to_anchor=(0.5, 0.94), ncol=len(labels_) + 1, fontsize=int(10 * scale), markerscale=4)\n",
    "\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "fig.subplots_adjust(top=0.80)\n",
    "fig.suptitle('Prediction Performance Across Parameters', fontsize=int(12*scale))\n",
    "\n",
    "# Save and show\n",
    "plt.savefig(f'{destination_folder}/true_vs_predicted_grid.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lite_grav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
